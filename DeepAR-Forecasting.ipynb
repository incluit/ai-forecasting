{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Material Quantity time-series with the DeepAR built-in algorithm on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en la data enviada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and pre-process data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minYear  = 2008\n",
    "maxYear  = 2018\n",
    "avg_quantity = 0\n",
    "\n",
    "# Our model will predict quantity for the next 'prediction_length' weeks\n",
    "prediction_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, boto3, json, sagemaker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open(filename, 'r')\n",
    "data = csv.reader(f,delimiter=';')\n",
    "\n",
    "dataset={}\n",
    "x=[]\n",
    "y=[]\n",
    "count=1\n",
    "prevYear=0\n",
    "\n",
    "for row in data:\n",
    "        # Remove empty strings caused by multiple spaces between columns\n",
    "        row = filter(None, row)\n",
    "        #print(row)\n",
    "        try:\n",
    "            year=row[2]\n",
    "            \n",
    "            quantity=float(row[4])+avg_quantity\n",
    "            # Data for plotting\n",
    "            # x list=counter, y list=quantity\n",
    "            x.append(count)\n",
    "            y.append(float(quantity))\n",
    "            count=count+1\n",
    "\n",
    "            # Data for training\n",
    "            # dictionary: key=year, value=list of ordered daily temperatures\n",
    "            if (year != prevYear):\n",
    "                dataset[year]=[]\n",
    "                prevYear=year\n",
    "            dataset[year].append(float(quantity))\n",
    "        except IndexError as error:\n",
    "            print(\"Ignoring line count: \", count,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples_per_year = list(map(lambda x: len(x), (dataset[str(year)] for year in range(minYear, maxYear+1))))\n",
    "nb_samples_per_year = np.unique(nb_samples_per_year).tolist()\n",
    "print(nb_samples_per_year)\n",
    "assert nb_samples_per_year == [52, 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nbSamples=len(x)\n",
    "print('Number of samples: %d' % nbSamples)\n",
    "\n",
    "fig=plt.figure(figsize=(64, 16))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html\n",
    "# - remove the last 'prediction_length' points from each time series\n",
    "# - use the full data set for testing\n",
    "# - no need to shuffle the training set: dictionaries are not ordered :)\n",
    "\n",
    "trainingSet = dataset.copy()\n",
    "trainingSet[year] = { year: dataset[year][:-prediction_length] for year in dataset.keys() }\n",
    "\n",
    "testSet = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet.pop('2018', None)\n",
    "testSet.pop('2018', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_key      = 'deepar_training.json'\n",
    "test_key       = 'deepar_test.json'\n",
    "\n",
    "def writeDataset(filename, data): \n",
    "    file=open(filename,'w')\n",
    "    for year in data.keys():\n",
    "        # One JSON sample per line\n",
    "        line = \"\\\"start\\\":\\\"{}-01-01 00:00:00\\\",\\\"target\\\":{}\".format(year,data[year])\n",
    "        file.write('{'+line+'}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeDataset(train_key, trainingSet)        \n",
    "writeDataset(test_key, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -20 deepar_training.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload training set and test set to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket         = 'forecasting-data'\n",
    "prefix         = 'prefix/curated'\n",
    "\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = '{}/{}'.format(prefix, 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role              = sagemaker.get_execution_role()\n",
    "region            = boto3.Session().region_name\n",
    "\n",
    "train_path  = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path   = sagemaker_session.upload_data(test_key,  bucket=bucket, key_prefix=test_prefix)\n",
    "output_path = 's3://{}/{}'.format(bucket, output_prefix)\n",
    "\n",
    "print(train_path)\n",
    "print(test_path)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {\n",
    "    'us-east-1': '522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:latest',\n",
    "    'us-east-2': '566113047672.dkr.ecr.us-east-2.amazonaws.com/forecasting-deepar:latest',\n",
    "    'us-west-2': '156387875391.dkr.ecr.us-west-2.amazonaws.com/forecasting-deepar:latest',\n",
    "    'eu-west-1': '224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:latest'\n",
    "}\n",
    "\n",
    "image_name = containers[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    #train_instance_type='ml.c4.8xlarge',\n",
    "    train_instance_type='ml.m4.2xlarge',\n",
    "    base_job_name='weekly-quantity',\n",
    "    output_path=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": 'W', # weekly series\n",
    "    \"context_length\": prediction_length,\n",
    "    \"prediction_length\": prediction_length, # number of data points to predict\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"2\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"250\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.00001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\" # stop if loss hasn't improved in 10 epochs\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_path)\n",
    "print(test_path)\n",
    "print(output_path)\n",
    "\n",
    "data_channels = {\"train\": train_path, \"test\": test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "job_name = estimator.latest_training_job.name\n",
    "\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.2xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "predictor = sagemaker.predictor.RealTimePredictor(\n",
    "    endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    content_type=\"application/json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build JSON-formatted prediction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = '0.1'         # compute p10 quantile\n",
    "q2 = '0.9'         # compute p90 quantile\n",
    "num_samples = 100  # predict 100 sample series\n",
    "    \n",
    "def buildPredictionData(year, data):\n",
    "    year_quantity = data[str(year)]\n",
    "    s = {\"start\": \"{}-01-01 00:00:00\".format(year), \"target\": year_quantity}\n",
    "    series = []\n",
    "    series.append(s)\n",
    "    configuration = {\n",
    "        \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\n",
    "        \"num_samples\": num_samples,\n",
    "        \"quantiles\": [q1, q2]\n",
    "    }\n",
    "    http_data = {\n",
    "        \"instances\": series, \n",
    "        \"configuration\": configuration\n",
    "    }\n",
    "\n",
    "    response = json.dumps(http_data)\n",
    "    \n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predicted series from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPredictedSeries(result):\n",
    "    import random\n",
    "    json_result = json.loads(result)\n",
    "    y_data      = json_result['predictions'][0]\n",
    "    y_mean      = y_data['mean']\n",
    "    y_q1        = y_data['quantiles'][q1]\n",
    "    y_q2        = y_data['quantiles'][q2]\n",
    "    y_sample    = y_data['samples'][random.randint(0, num_samples)]\n",
    "\n",
    "    print(\"Mean: %s\\n\" % y_mean)\n",
    "    print(\"Quartile %s: %s\\n\" % (q1, y_q1))\n",
    "    print(\"Quartile %s: %s\\n\" % (q2, y_q2))\n",
    "    return y_mean, y_q1, y_q2, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predicted series and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSeries(result, truth=False, truth_data=None, truth_label=None):\n",
    "    x = range(0,prediction_length)\n",
    "    y_mean, y_q1, y_q2, y_sample = getPredictedSeries(result)\n",
    "    plt.gcf().clear()\n",
    "    mean_label,   = plt.plot(x, y_mean, label='mean')\n",
    "    q1_label,     = plt.plot(x, y_q1, label=q1)\n",
    "    q2_label,     = plt.plot(x, y_q2, label=q2)\n",
    "    sample_label, = plt.plot(x, y_sample, label='sample')\n",
    "\n",
    "    if truth:\n",
    "        ground_truth, = plt.plot(x, truth_data, label=truth_label)\n",
    "        plt.legend(handles=[ground_truth, q2_label, mean_label, q1_label, sample_label])\n",
    "    else:\n",
    "        plt.legend(handles=[q2_label, mean_label, q1_label, sample_label])\n",
    "    plt.yticks(np.arange(5.0, 12.0, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: predict Quantity for the last 'prediction_length' days and compare to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2016 # “He who controls the past controls the future. He who controls the present controls the past.”\n",
    "\n",
    "prediction_data = buildPredictionData(year, trainingSet)\n",
    "\n",
    "result = predictor.predict(prediction_data).encode('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: predict Quantity for the next 'prediction_length' days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict quantity for the next 'prediction_length' weeks of 2018\n",
    "year = 2018\n",
    "year_quantity={}\n",
    "year_quantity[str(year)] = np.random.normal(9, 1.5, 90).tolist()\n",
    "\n",
    "prediction_data = buildPredictionData(year, year_quantity)\n",
    "\n",
    "result = predictor.predict(prediction_data).encode('utf-8')\n",
    "print(\"Result...\")\n",
    "print(result)\n",
    "filename      = 'results.csv'\n",
    "file=open(filename,'w')\n",
    "file.write(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_name)\n",
    "sm = boto3.client('sagemaker')\n",
    "sm.delete_endpoint(EndpointName=job_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=job_name)\n",
    "sm.delete_model(ModelName=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
